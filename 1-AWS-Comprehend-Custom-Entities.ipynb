{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1099b04396475b6a0143fa303da9fa44ad87b660"
   },
   "source": [
    "# How to prepare a dataset and submit a custom entity recognizer for Amazon Comprehend\n",
    "\n",
    "This notebook walks through how to prepare a training dataset for custom entities in Amazon Comprehend\n",
    "\n",
    "More information on how to create a custom entity recognizer model can be found here.\n",
    "\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/training-recognizers.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::202860692096:role/service-role/AmazonSageMaker-ExecutionRole-20180529T141286\n"
     ]
    }
   ],
   "source": [
    "# library imports\n",
    "import boto3\n",
    "\n",
    "import botocore\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "# Specify S3 bucket and prefix that you want to use for model data\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = '<bucket>'\n",
    "prefix = 'comprehend-custom-entity'\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54e810d8b9c1936c8569093badabc4d7b25ea881"
   },
   "source": [
    "In this example we will be using the following twitter dataset. https://www.kaggle.com/thoughtvector/customer-support-on-twitter\n",
    "Download the dataset and save it in the ./data folder.\n",
    "\n",
    "If you don't have an account ok kaggle you can run the following commands from the notebook terminal.\n",
    "\n",
    "aws s3 cp s3://phi-demo-london/twcs/twcs.zip /home/ec2-user/SageMaker/amazon-comprehend-custom-entity/data/twcs.zip\n",
    "\n",
    "cd /home/ec2-user/SageMaker/amazon-comprehend-custom-entity/data\n",
    "\n",
    "unzip twcs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9365c16e4481ec49f5c084f7c3b0cf50dd55047f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2811774, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('./data/twcs.csv',encoding='utf-8')\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "845eba8749f15e1e2b10aa43414f40860259f4e0"
   },
   "source": [
    "<a id='data-wrangling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e053048057a5566a30aab3f0278aa529449938a"
   },
   "source": [
    "## Data Wrangling\n",
    "\n",
    "This is a very interesting tweet data set, about 3 million tweets, and we have information on the author of the tweets and whether the tweet was a query or a response (the \"inbound\" column). If the tweet was a query, the response_tweet_id gives the response made by the support team.\n",
    "\n",
    "It would be interesting to modify this dataframe to get query - response pairs in every row.\n",
    "The following code, to do just what we want, was pulled from [this kernel](https://www.kaggle.com/soaxelbrooke/first-inbound-and-response-tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (794299, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 19:59:13 +0000 2017</td>\n",
       "      <td>@115713 H there! We'd definitely like to work ...</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>115715</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:10 +0000 2017</td>\n",
       "      <td>@115715 Please send me a private message so th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
       "0           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "1           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "2           8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3          18      115713       True  Tue Oct 31 19:56:01 +0000 2017   \n",
       "4          20      115715       True  Tue Oct 31 22:03:34 +0000 2017   \n",
       "\n",
       "                                              text_x response_tweet_id_x  \\\n",
       "0          @sprintcare is the worst customer service              9,6,10   \n",
       "1          @sprintcare is the worst customer service              9,6,10   \n",
       "2          @sprintcare is the worst customer service              9,6,10   \n",
       "3  @115714 y’all lie about your “great” connectio...                  17   \n",
       "4  @115714 whenever I contact customer support, t...                  19   \n",
       "\n",
       "   in_response_to_tweet_id_x  tweet_id_y author_id_y  inbound_y  \\\n",
       "0                        NaN           6  sprintcare      False   \n",
       "1                        NaN           9  sprintcare      False   \n",
       "2                        NaN          10  sprintcare      False   \n",
       "3                        NaN          17  sprintcare      False   \n",
       "4                        NaN          19  sprintcare      False   \n",
       "\n",
       "                     created_at_y  \\\n",
       "0  Tue Oct 31 21:46:24 +0000 2017   \n",
       "1  Tue Oct 31 21:46:14 +0000 2017   \n",
       "2  Tue Oct 31 21:45:59 +0000 2017   \n",
       "3  Tue Oct 31 19:59:13 +0000 2017   \n",
       "4  Tue Oct 31 22:10:10 +0000 2017   \n",
       "\n",
       "                                              text_y response_tweet_id_y  \\\n",
       "0  @115712 Can you please send us a private messa...                 5,7   \n",
       "1  @115712 I would love the chance to review the ...                 NaN   \n",
       "2  @115712 Hello! We never like our customers to ...                 NaN   \n",
       "3  @115713 H there! We'd definitely like to work ...                  16   \n",
       "4  @115715 Please send me a private message so th...                 NaN   \n",
       "\n",
       "   in_response_to_tweet_id_y  \n",
       "0                        8.0  \n",
       "1                        8.0  \n",
       "2                        8.0  \n",
       "3                       18.0  \n",
       "4                       20.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
    "\n",
    "QnR = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id')\n",
    "\n",
    "# Filter to only outbound replies (from companies)\n",
    "QnR = QnR[QnR.inbound_y ^ True]\n",
    "print(f'Data shape: {QnR.shape}')\n",
    "QnR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0428e41c670dbe801090613580cf22e3b41723b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115713</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 19:59:13 +0000 2017</td>\n",
       "      <td>@115713 H there! We'd definitely like to work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115715</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 22:10:10 +0000 2017</td>\n",
       "      <td>@115715 Please send me a private message so th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author_id_x                    created_at_x  \\\n",
       "0      115712  Tue Oct 31 21:45:10 +0000 2017   \n",
       "1      115712  Tue Oct 31 21:45:10 +0000 2017   \n",
       "2      115712  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3      115713  Tue Oct 31 19:56:01 +0000 2017   \n",
       "4      115715  Tue Oct 31 22:03:34 +0000 2017   \n",
       "\n",
       "                                              text_x author_id_y  \\\n",
       "0          @sprintcare is the worst customer service  sprintcare   \n",
       "1          @sprintcare is the worst customer service  sprintcare   \n",
       "2          @sprintcare is the worst customer service  sprintcare   \n",
       "3  @115714 y’all lie about your “great” connectio...  sprintcare   \n",
       "4  @115714 whenever I contact customer support, t...  sprintcare   \n",
       "\n",
       "                     created_at_y  \\\n",
       "0  Tue Oct 31 21:46:24 +0000 2017   \n",
       "1  Tue Oct 31 21:46:14 +0000 2017   \n",
       "2  Tue Oct 31 21:45:59 +0000 2017   \n",
       "3  Tue Oct 31 19:59:13 +0000 2017   \n",
       "4  Tue Oct 31 22:10:10 +0000 2017   \n",
       "\n",
       "                                              text_y  \n",
       "0  @115712 Can you please send us a private messa...  \n",
       "1  @115712 I would love the chance to review the ...  \n",
       "2  @115712 Hello! We never like our customers to ...  \n",
       "3  @115713 H there! We'd definitely like to work ...  \n",
       "4  @115715 Please send me a private message so th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's filter the dataframe contains only the needed columns\n",
    "QnR = QnR[[\"author_id_x\",\"created_at_x\",\"text_x\",\"author_id_y\",\"created_at_y\",\"text_y\"]]\n",
    "QnR.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to only telco tweets\n",
    "In our example, we want to create a custom entity to recognize smartphones devices. Let's filer our dataframe to only incclude the T-Mobile and Sprint tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco = QnR[QnR[\"author_id_y\"].isin([\"TMobileHelp\", \"sprintcare\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concatenate the question and response into one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tweet_telco['text'] = tweet_telco['text_x'] + ' | ' + tweet_telco['text_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our telco tweets as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweet_telco['text'].to_csv('./data/tweet_telco.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity list\n",
    "In order to create our dataset we need to provide an entity list for our new class named DEVICE.\n",
    "\n",
    "In the second notebook, we load a corpus into a word2vec model and generate a list of keywords that are contextually similar. This technique will be used in the custom classifer in the third notebook. The same technique could be applied here.\n",
    "\n",
    "For now, in order to create our entity list, we will generate keywords of different smartphones manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphones = ['iPhone X', 'iPhoneX', 'iphoneX', 'Samsung Galaxy', 'Samsung Note', 'iphone', 'iPhone', 'android', 'Android']\n",
    "\n",
    "df_entity_list = pd.DataFrame(sphones, columns=['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's add another column with our class label. This is required part of the Amazon Comprehend training dataset.\n",
    "\n",
    "More information can be found here.\n",
    "\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/cer-entity-list.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity_list['Type'] = 'DEVICE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone X</td>\n",
       "      <td>DEVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhoneX</td>\n",
       "      <td>DEVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iphoneX</td>\n",
       "      <td>DEVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy</td>\n",
       "      <td>DEVICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Note</td>\n",
       "      <td>DEVICE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Text    Type\n",
       "0        iPhone X  DEVICE\n",
       "1         iPhoneX  DEVICE\n",
       "2         iphoneX  DEVICE\n",
       "3  Samsung Galaxy  DEVICE\n",
       "4    Samsung Note  DEVICE"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entity_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our training, entity list, and test file and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "training_file = './data/telco_train.csv'\n",
    "tweet_telco['text'].to_csv(training_file, encoding='utf-8', index=False)\n",
    "\n",
    "entity_file = './data/entity_list.csv'\n",
    "df_entity_list.to_csv(entity_file, encoding='utf-8', index=False)\n",
    "\n",
    "test_file = './data/telco_device_test.csv'\n",
    "tweet_telco['text'].tail(10000).to_csv(test_file, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(s3path, file):\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, \"rb\")\n",
    "    key = s3path\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "s3_train_key = prefix + \"/train/telco_train.csv\" \n",
    "s3_test_key = prefix + \"/test/telco_device_test.csv\"\n",
    "s3_entity_key = prefix + \"/entity/telco_entity.csv\"\n",
    "\n",
    "upload_to_s3(s3_train_key, training_file)\n",
    "upload_to_s3(s3_test_key, test_file)\n",
    "upload_to_s3(s3_entity_key, entity_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://data-phi/comprehend-custom-entity/train/telco_train.csv\n"
     ]
    }
   ],
   "source": [
    "#Create s3 paths variable \n",
    "s3_train_data = 's3://{}/{}'.format(bucket, s3_train_key)\n",
    "s3_train_entity = 's3://{}/{}'.format(bucket, s3_entity_key)\n",
    "s3_test_data = 's3://{}/{}'.format(bucket, s3_test_key)\n",
    "s3_output_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, \"telco_test_output.json\")\n",
    "print('uploaded training data location: {}'.format(s3_train_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Let's prepare the Custom Entity training job request file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_entity_request = {\n",
    "\n",
    "      \"Documents\": { \n",
    "         \"S3Uri\": s3_train_data\n",
    "      },\n",
    "      \"EntityList\": { \n",
    "         \"S3Uri\": s3_train_entity\n",
    "      },\n",
    "      \"EntityTypes\": [ \n",
    "         { \n",
    "            \"Type\": \"DEVICE\"\n",
    "         }\n",
    "      ]\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "create_custom_entity_response = comprehend.create_entity_recognizer(\n",
    "        RecognizerName = \"custom-device-recognizer\"+id, \n",
    "        DataAccessRoleArn = role,\n",
    "        InputDataConfig = custom_entity_request,\n",
    "        LanguageCode = \"en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom entity recognizer: SUBMITTED\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINING\n",
      "Custom entity recognizer: TRAINED\n"
     ]
    }
   ],
   "source": [
    "jobArn = create_custom_entity_response['EntityRecognizerArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_custom_recognizer = comprehend.describe_entity_recognizer(\n",
    "        EntityRecognizerArn = jobArn\n",
    "    )\n",
    "    status = describe_custom_recognizer[\"EntityRecognizerProperties\"][\"Status\"]\n",
    "    print(\"Custom entity recognizer: {}\".format(status))\n",
    "    \n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the different metrics for our custom entity recognizer. More information can be found here.\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/cer-metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"Type\": \"DEVICE\",\n",
      "    \"EvaluationMetrics\": {\n",
      "      \"Precision\": 99.12023460410558,\n",
      "      \"Recall\": 100.0,\n",
      "      \"F1Score\": 99.55817378497791\n",
      "    },\n",
      "    \"NumberOfTrainMentions\": 2764\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(describe_custom_recognizer[\"EntityRecognizerProperties\"][\"RecognizerMetadata\"][\"EntityTypes\"], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our custom entity model\n",
    "\n",
    "Let's invoke the Comprehend API to run our test job from the test file we prepared earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = comprehend.start_entities_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_test_data,\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_test_data\n",
    "    },\n",
    "    DataAccessRoleArn=role,\n",
    "    JobName='Custom_Device_Test',\n",
    "    EntityRecognizerArn=jobArn,\n",
    "    LanguageCode='en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's monitor the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: IN_PROGRESS\n",
      "Job Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "jobId = test_response['JobId']\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_job = comprehend.describe_entities_detection_job(\n",
    "        JobId = jobId\n",
    "    )\n",
    "    status = describe_job[\"EntitiesDetectionJobProperties\"][\"JobStatus\"]\n",
    "    print(\"Job Status: {}\".format(status))\n",
    "    \n",
    "    if status == \"COMPLETED\" or status == \"FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the test output to local machine\n",
    "job_output = describe_job[\"EntitiesDetectionJobProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "path_prefix = 's3://{}/'.format(bucket)\n",
    "job_key = os.path.relpath(job_output, path_prefix)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(job_key, 'output.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\r\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n",
      "iPhone\n",
      "Samsung Note\n",
      "android\n",
      "iphone\n",
      "Samsung Glxy\n",
      "Android\n",
      "Pure X\n",
      "iphonex\n",
      "iPhoneX\n",
      "iphoneX\n",
      "Samsung galaxy\n",
      "Samsung Galaxy\n",
      "newiPhone X\n"
     ]
    }
   ],
   "source": [
    "#Load all the Entities values in a list\n",
    "import json\n",
    "\n",
    "data = []\n",
    "for line in open('output', 'r'):\n",
    "    entities = json.loads(line)['Entities']\n",
    "    if entities != None and len(entities) > 0:\n",
    "        data.append(entities[0]['Text'])\n",
    "    \n",
    "\n",
    "# function to get unique values \n",
    "def unique(list1): \n",
    "      \n",
    "    # insert the list to the set \n",
    "    list_set = set(list1) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(list_set)) \n",
    "    for x in unique_list: \n",
    "        print(x), \n",
    "        \n",
    "unique(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
