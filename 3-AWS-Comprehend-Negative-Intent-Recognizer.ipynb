{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom negativity intent recognizer.\n",
        "\n",
        "This notebook covers how to prepare a training dataset for custom entities in Amazon Comprehend leveraging the custom keywords that were generated from our word2vec model. \n",
        "\n",
        "We will build custom negativity intent recognizer based on keywords semantically similar to the word \"frustrated\"\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "1099b04396475b6a0143fa303da9fa44ad87b660"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# library imports\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import csv\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example we will re-use the dataset that we wrangled and filtered for the telco domain. "
      ],
      "metadata": {
        "_uuid": "54e810d8b9c1936c8569093badabc4d7b25ea881"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colnames=['text'] \n",
        "tweets = pd.read_csv('./data/tweet_telco.csv',encoding='utf-8',names=colnames, header=None)\n",
        "print(tweets.shape)\n",
        "tweets.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32716, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@sprintcare is the worst customer service | @1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@sprintcare is the worst customer service | @1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@sprintcare is the worst customer service | @1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@115714 whenever I contact customer support, t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  @sprintcare is the worst customer service | @1...\n",
              "1  @sprintcare is the worst customer service | @1...\n",
              "2  @sprintcare is the worst customer service | @1...\n",
              "3  @115714 y’all lie about your “great” connectio...\n",
              "4  @115714 whenever I contact customer support, t..."
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "_uuid": "9365c16e4481ec49f5c084f7c3b0cf50dd55047f",
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='data-wrangling'></a>"
      ],
      "metadata": {
        "_uuid": "845eba8749f15e1e2b10aa43414f40860259f4e0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create our dataset we need to provide an entity list for our new class named NEGATIVITY.\n",
        "\n",
        "In order to find relevant entities, we will be using our custom word2vec model to find semantically similar words to \"frustrated\". See the blazingtext_word2vec_telco_tweets.ipynb notebook for generating keywords."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "negative_words = ['Really', 'cheated', 'annoyed', 'unhelpful', 'frustrated', 'upset' , 'unhappy', 'angry', 'badly', 'bad', 'surprised', 'sadly', 'dissatisfied', 'disappointed', 'disgusted']\n",
        "\n",
        "df_entity_list = pd.DataFrame(negative_words, columns=['Text'])\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's add another column with our class label. This is required part of the Amazon Comprehend training dataset.\n",
        "\n",
        "More information can be found here.\n",
        "\n",
        "https://docs.aws.amazon.com/comprehend/latest/dg/cer-entity-list.html\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_entity_list['Type'] = 'NEGATIVE'\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create our training file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'].to_csv('./data/raw_negative.csv', encoding='utf-8', index=False)\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!head ./data/raw_negative.csv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"@115911 @TMobileHelp y’all just pissed me off and I’m highly disappointed with the customer service been with y’all over 16 years FIX THIS! | @117690 Hey bro! Send me a DM, I got you 100% - https://t.co/UOOUCn8nWm *JeremyKelley\"\r\n",
            "\"@115714 sucks so bad. Always switching to roaming so they can charge me whatever the hell they want. Get a real network! | @117883 We'd be more than willing to take a look at the area for you if you can DM us a good intersection, J. :) -CDE\"\r\n",
            "\"Mad at Sprint, daughter had her phone stolen and we are getting the rum around trying to get her a new one. #Sprint  #frustrated | @117885 This is concerning to us. Please, send us a DM with more details of your issue for us to assist you further. -DP\"\r\n",
            "\"@115911 @TMobileHelp terrible customer service. 3 dysfunctional refurbished phones in 2 weeks. @115913 #badservice | @120051 Ni Nicos, thank you for reaching out to us. I replied to your DM and look forward to working with you. *JasonYaddow\"\r\n",
            "\"@115913 so upset with @115911, honestly don't know why I stay, the customer care line is so rude \"\"hold on! First tell me the reason why you are calling\"\" I'm so done! Literally cried while on the phone with them. So much emotional abuse at their hands | @122611 @115913 Hi Lizbeth. This is truly not the experience I want for you. You deserve the best customer service we've got. Send me a DM so we can get started on turning this around. https://t.co/3sF8qpf2nx *AlissaFast\"\r\n",
            "@115911 they’re so not transparent that you can speak to 9 reps and get 9 versions of their truths... #tmobilesucks #annoyedcustomer | @124339 We can understand your frustration Romy. Allow us to look into why this is happening. Please send us a DM. *KaeW\r\n",
            "\"owe to me. Truly disappointed in the customer support and over all company morals of @115911 . | @125456 James, you deserve to have your device. DM us and let's see what happened so we can turn this around for you. *JamieK\"\r\n",
            "\"In the @115714 store cancellimg my account and @sprintcare is so bad they hung up on me and the guy who works at this location #sprintsucks | @125736 Jay, we really hate to hear that you want to leave Sprint; is there anything that we can do to turn this around? -CDE\"\r\n",
            "Really sick of paying 100 a month for dropped calls and no internet service. @sprintcare is there anything you will do for me? | @125913 Can you please send me a DM so that I can take a look at your concern? -BJ https://t.co/rMApsV8PQY\r\n",
            "@115911 why does our coverage suck soooo bad in rural areas? | @127781 What rural areas are you referring to Domino? Let us know those location in a DM so that we can look into it. *KaeW\r\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create the entity list file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_entity_list.to_csv('./data/entity_negative_list.csv', encoding='utf-8', index=False)\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!head ./data/entity_negative_list.csv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text,Type\r\n",
            "Really,NEGATIVE\r\n",
            "cheated,NEGATIVE\r\n",
            "annoyed,NEGATIVE\r\n",
            "unhelpful,NEGATIVE\r\n",
            "frustrated,NEGATIVE\r\n",
            "upset,NEGATIVE\r\n",
            "unhappy,NEGATIVE\r\n",
            "angry,NEGATIVE\r\n",
            "badly,NEGATIVE\r\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a test file from our original telco tweet dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tweets['text'].tail(10000).to_csv('./data/telco_device_test.csv', encoding='utf-8', index=False)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training our model\n",
        "\n",
        "I am going to use the console to submit our custom entity recognizer job. Look at the first notebook for details.\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing our custom entity model\n",
        "\n",
        "Let's invoke the Comprehend API to run our test job from the test file we prepared earlier."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "aws comprehend start-entities-detection-job \\\n",
        "     --entity-recognizer-arn \"arn:aws:comprehend:us-east-1:202860692096:entity-recognizer/Negativity-copy\" \\\n",
        "     --job-name Test \\\n",
        "     --data-access-role-arn \"arn:aws:iam::202860692096:role/service-role/AmazonComprehendServiceRole-AmazonComprehendServiceRole\" \\\n",
        "     --language-code en \\\n",
        "     --input-data-config \"S3Uri=s3://data-phi/telco_random.csv\" \\\n",
        "     --output-data-config \"S3Uri=s3://data-phi/telco_negative\" \\\n",
        "     --region \"us-east-1\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output will be a json file specified in my --output-data-config.\n",
        "You can use Glue and Athena to inspect the results.\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "39751a13337cd09b32588e2d0fc5f7e7817cca8b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}